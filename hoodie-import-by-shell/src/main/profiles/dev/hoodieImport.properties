hoodie.insert.shuffle.parallelism=2
hoodie.upsert.shuffle.parallelism=2
hoodie.datasource.write.storage.type=COPY_ON_WRITE
hoodie.datasource.write.recordkey.field=rowkey
hoodie.datasource.write.precombine.field=lastupdatedttm
hoodie.datasource.write.partitionpath.field=fk_id
hoodie.datasource.hive_sync.jdbcurl=jdbc:hive2://192.168.0.111:10000/xh
#hoodie.datasource.hive_sync.jdbcurl=jdbc:hive2://master:10000/xh;principal=hive/master@HADOOP.COM
hoodie.datasource.hive_sync.username=hive
hoodie.datasource.hive_sync.password=hive

# kerberos
hoodie.import.kerberos.enable=false
hoodie.import.kerberos.krb5.path=E:\\conf\\nvwa\\local\\krb5.conf
hoodie.import.kerberos.keytab=E:\\conf\\nvwa\\local\\hdfs.keytab
hoodie.import.kerberos.user.principal=hdfs/master@HADOOP.COM
hoodie.import.hadoop.conf.dir=E:\\conf\\nvwa\\local\\hadoop

#ssh
hoodie.import.ssh.hudi.hive.sync.host=192.168.0.28
hoodie.import.ssh.hudi.hive.sync.port=22
hoodie.import.ssh.hudi.hive.sync.user=root
hoodie.import.ssh.hudi.hive.sync.pass=P@ssw0rd123
hoodie.import.ssh.hudi.hive.sync.shell.path=/opt/hudi/hudi-hive-sync/run_sync_tool.sh